import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import altair as alt

# ======================================
st.set_page_config("Ruleâ€‘Basedâ€¯Intradayâ€¯Optionâ€¯Signals", layout="wide")
st.title("ðŸ“Š Ruleâ€‘Basedâ€¯Intradayâ€¯Optionâ€¯Signalâ€¯System â€“ Finalâ€¯Edition")

# ---- SIDEBAR ----
rolling_n = st.sidebar.number_input("Rollingâ€¯windowâ€¯(bars)", 3, 60, 5)
spread_cutoff = st.sidebar.slider("Maxâ€¯bidâ€‘askâ€¯spreadâ€¯%", 0.0, 1.0, 0.2)
basis = st.sidebar.radio("Topâ€‘strikeâ€¯rankingâ€¯basis", ["Openâ€¯Interest", "Volume"])
num_strikes = st.sidebar.number_input("Topâ€¯strikesâ€¯byâ€¯basis", 1, 30, 6)
st.sidebar.markdown("Uploadâ€¯**Optionâ€‘Chainâ€¯CSVâ€¯files**â€¯ðŸ‘‡")

uploaded = st.file_uploader("Dropâ€¯CSVâ€¯filesâ€¯(multipleâ€¯allowed)",
                             type=["csv"], accept_multiple_files=True)
if not uploaded:
    st.info("â¬…ï¸â€¯Uploadâ€¯CSVsâ€¯toâ€¯start.")
    st.stop()

# ---- LOAD ----
frames=[]
for f in uploaded:
    try:
        base=f.name.replace(".csv","")
        ts=datetime.strptime(base.split("_")[-2]+"_"+base.split("_")[-1],"%d%m%Y_%H%M%S")
    except Exception:
        ts=datetime.now()
    df=pd.read_csv(f)
    df["timestamp"]=ts
    frames.append(df)

raw=pd.concat(frames,ignore_index=True).sort_values("timestamp")
st.success(f"âœ…â€¯Loadedâ€¯{len(uploaded)}â€¯file(s),â€¯{len(raw)}â€¯rowsâ€¯total.")

# ---- CLEAN ----
def clean_data(df,cuto=0.2):
    df=df.copy()
    df["timestamp"]=pd.to_datetime(df["timestamp"],errors="coerce")
    req=["CE_buyPrice1","CE_sellPrice1","PE_buyPrice1","PE_sellPrice1"]
    avail=[c for c in req if c in df.columns]
    df=df[(df[avail]>0).all(axis=1)]
    df["mid_CE"]=(df["CE_buyPrice1"]+df["CE_sellPrice1"])/2
    df["mid_PE"]=(df["PE_buyPrice1"]+df["PE_sellPrice1"])/2
    df["mid_CE"].replace(0,np.nan,inplace=True)
    df["spread_pct"]=abs(df["CE_sellPrice1"]-df["CE_buyPrice1"])/df["mid_CE"]
    df=df[df["spread_pct"]<cuto]
    if "CE_expiryDate" in df.columns:
        df["CE_expiryDate"]=pd.to_datetime(df["CE_expiryDate"],errors="coerce")
        df["days_to_expiry"]=(df["CE_expiryDate"]-df["timestamp"]).dt.days
    else:
        df["days_to_expiry"]=1
    df["days_to_expiry"].fillna(1,inplace=True)
    df["Î¸_adj_CE"]=df["CE_lastPrice"]/np.sqrt(df["days_to_expiry"].clip(lower=1))
    df["Î¸_adj_PE"]=df["PE_lastPrice"]/np.sqrt(df["days_to_expiry"].clip(lower=1))
    return df

df=clean_data(raw,spread_cutoff)

# ---- UTILS ----
def rolling_corr(a,b,window=10,minp=3):
    arr=np.full(len(a),np.nan)
    for i in range(window,len(a)):
        xa,xb=a[i-window:i],b[i-window:i]
        if np.std(xa)>1e-8 and np.std(xb)>1e-8:
            arr[i]=np.corrcoef(xa,xb)[0,1]
    return pd.Series(arr).fillna(method="bfill").fillna(0)

# ---- FEATURES ----
def compute_features(df,rolling_n=5,top_n=6,basis="Openâ€¯Interest"):
    df=df.copy().sort_values("timestamp")
    df["CE_vol_delta"]=df.groupby("CE_strikePrice")["CE_totalTradedVolume"].diff().fillna(0)
    df["PE_vol_delta"]=df.groupby("CE_strikePrice")["PE_totalTradedVolume"].diff().fillna(0)
    df["total_vol"]=df["CE_vol_delta"]+df["PE_vol_delta"]
    df["total_OI"]=df["CE_openInterest"]+df["PE_openInterest"]
    metric="total_OI" if basis.startswith("Open") else "total_vol"
    mean_strike=df.groupby("CE_strikePrice")[metric].mean()
    top_strikes=mean_strike.nlargest(top_n)
    covered_pct=round(100*top_strikes.sum()/mean_strike.sum(),2)
    df=df[df["CE_strikePrice"].isin(top_strikes.index)]

    agg=df.groupby("timestamp").agg({
        "CE_lastPrice":"mean","PE_lastPrice":"mean",
        "CE_openInterest":"sum","PE_openInterest":"sum",
        "CE_changeinOpenInterest":"sum","PE_changeinOpenInterest":"sum",
        "CE_vol_delta":"sum","PE_vol_delta":"sum",
        "CE_impliedVolatility":"mean","PE_impliedVolatility":"mean"
    })
    # core diffs
    agg["Î”Price_CE"]=agg["CE_lastPrice"].diff()
    agg["Î”OI_CE"]=agg["CE_changeinOpenInterest"].diff()
    agg["Î”Price_PE"]=agg["PE_lastPrice"].diff()
    agg["Î”OI_PE"]=agg["PE_changeinOpenInterest"].diff()
    agg["IV_skew"]=agg["CE_impliedVolatility"]-agg["PE_impliedVolatility"]
    agg["Î”IV"]=agg["IV_skew"].diff()
    agg["PCR_OI"]=agg["PE_openInterest"]/agg["CE_openInterest"].replace(0,np.nan)
    agg["Î”PCR"]=agg["PCR_OI"].diff()
    total_vol=agg["CE_vol_delta"]+agg["PE_vol_delta"]
    agg["Volume_spike"]=total_vol/total_vol.rolling(rolling_n).mean()

    # advanced metrics
    agg["VWAP"]=(
        (agg["CE_lastPrice"]*agg["CE_vol_delta"] + agg["PE_lastPrice"]*agg["PE_vol_delta"])
        /(agg["CE_vol_delta"]+agg["PE_vol_delta"]).replace(0,np.nan)
    ).fillna(method="ffill")
    agg["Î”VWAP"]=agg["VWAP"].diff()
    agg["Vol_imbalance"]=(agg["CE_vol_delta"]-agg["PE_vol_delta"])/(agg["CE_vol_delta"]+agg["PE_vol_delta"]).replace(0,np.nan)
    agg["Absorption_idx"]=agg["CE_vol_delta"].abs()/(agg["Î”OI_CE"].abs()+1)
    agg["Cum_tick_flow"]=np.cumsum(np.sign(agg["Î”Price_CE"].fillna(0))*agg["CE_vol_delta"])
    agg["Corr_PriceVol"]=rolling_corr(agg["Î”Price_CE"].values,agg["CE_vol_delta"].values,window=rolling_n)
    agg["Corr_IVVol"]=rolling_corr(agg["Î”IV"].values,agg["Volume_spike"].values,window=rolling_n)
    agg.fillna(0,inplace=True)
    return agg,covered_pct

df_feat,covered_pct=compute_features(df,rolling_n,num_strikes,basis)
st.caption(f"Topâ€¯{num_strikes}â€¯strikesâ€¯â‰ˆâ€¯{covered_pct}%â€¯ofâ€¯totalâ€¯{basis.lower()} coverage.")

# ---- LOGIC ----
def detect_regime(row):
    reg,bias="quiet","neutral"
    if row["Î”Price_CE"]*row["Î”OI_CE"]>0 and row["Volume_spike"]>1: reg="trend"
    elif abs(row["Î”Price_CE"])<0.05 and abs(row["Î”OI_CE"])<1000: reg="range"
    elif abs(row["Î”Price_CE"])>0.2 and row["Volume_spike"]>1.5 and row["Î”IV"]>0: reg="breakout"
    elif row["Î”Price_CE"]>0 and row["Î”OI_CE"]<0 and row["Î”IV"]<0: reg="exhaustion"
    if row["PCR_OI"]<0.8: bias="bullish"
    elif row["PCR_OI"]>1.2: bias="bearish"
    return reg,bias

def generate_signal(row):
    if row["regime"]=="trend" and row["bias"]=="bullish": return "BUY_CALL"
    if row["regime"]=="trend" and row["bias"]=="bearish": return "BUY_PUT"
    if row["regime"]=="range": return "SELL_STRANGLE"
    if row["regime"]=="breakout": return "MOMENTUM_TRADE"
    if row["regime"]=="exhaustion": return "EXIT_POSITION"
    return "HOLD"

df_feat[["regime","bias"]]=df_feat.apply(detect_regime,axis=1,result_type="expand")
df_feat["signal"]=df_feat.apply(generate_signal,axis=1)
df_feat["signal_numeric"]=df_feat["signal"].map({
    "BUY_CALL":1,"BUY_PUT":1,"MOMENTUM_TRADE":1,
    "SELL_STRANGLE":0,"HOLD":0,"EXIT_POSITION":-1
}).fillna(0)

# ---- HUMAN INTERPRETATIONS ----
def signal_summary(r):
    txt=[]
    # Volume imbalance meaning
    if r["Vol_imbalance"]>0.3:
        txt.append("Call volume dominant â†’ market leaning bullish.")
    elif r["Vol_imbalance"]<-0.3:
        txt.append("Put volume dominant â†’ market leaning bearish.")
    else:
        txt.append("Balanced flow across calls/puts.")
    # VWAP shift
    if r["Î”VWAP"]>0: txt.append("VWAP rising â†’ buyers lifting offers.")
    elif r["Î”VWAP"]<0: txt.append("VWAP falling â†’ sellers hitting bids.")
    else: txt.append("VWAP stable â†’ sideways flows.")
    # Correlation layer
    if r["Corr_PriceVol"]>0.5: txt.append("Strong +corr: conviction buying.")
    elif r["Corr_PriceVol"]<-0.5: txt.append("Negative corr: distribution/absorption.")
    # Absorption / IV confirmation
    if r["Absorption_idx"]<1: txt.append("Low absorption_idxâ€¯(<1) â†’ Smart money absorbing volume, possible reversal.")
    if r["Corr_IVVol"]>0.4: txt.append("IV rising with volume â†’ speculative buildâ€‘up.")
    elif r["Corr_IVVol"]<-0.4: txt.append("IV dropping with volume â†’ hedge unwind.")
    # Final inference
    concl="Stable bias; CE & PE may stay rangeâ€‘bound."
    if r["Vol_imbalance"]>0.3 and r["Î”VWAP"]>0: concl="CE prices likely to rise; PE soften."
    elif r["Vol_imbalance"]<-0.3 and r["Î”VWAP"]<0: concl="PE prices likely to rise; CE weaken."
    txt.append("ðŸ§­ "+concl)
    return "\n".join(txt)

df_feat["Implied_Signal_Text"]=df_feat.apply(signal_summary,axis=1)

# ---- METRICS ----
lat=df_feat.iloc[-1]
c1,c2,c3,c4=st.columns(4)
c1.metric("Currentâ€¯PCRâ€¯(OI)",round(float(lat["PCR_OI"]),2))
c2.metric("Trendâ€¯Bars",int((df_feat["regime"]=="trend").sum()))
c3.metric("Latestâ€¯Signal",lat["signal"])
c4.metric("Rowsâ€¯Processed",len(df_feat))

# ---- DETAILED TABLE ----
st.subheader("ðŸ“‹ Detailedâ€¯Signalsâ€¯â€“â€¯Allâ€¯Timestamps")
cols_show=[
    "signal","bias","regime","Vol_imbalance","Î”VWAP","Corr_PriceVol",
    "Absorption_idx","Corr_IVVol","PCR_OI","Implied_Signal_Text"
]
st.dataframe(df_feat[cols_show],use_container_width=True)

# ---- HUMAN INTERPRETATION OF VOLUME/ VWAP TRENDS ----
st.subheader("ðŸ”â€¯Volumeâ€¯Imbalanceâ€¯&â€¯VWAPâ€¯Trendâ€¯Insights")

def interpret_volume_vwap(agg):
    last=agg.iloc[-1]
    lines=[]
    if last["Vol_imbalance"]>0.3 and last["Î”VWAP"]>0:
        lines.append("âœ…â€¯Strong callâ€‘side buying with rising VWAP: trend supportive of CE price gains.")
    elif last["Vol_imbalance"]<-0.3 and last["Î”VWAP"]<0:
        lines.append("âš ï¸â€¯Heavy putâ€‘side flow with falling VWAP: indicates downward momentum.")
    elif abs(last["Vol_imbalance"])<0.2 and abs(last["Î”VWAP"])<0.02:
        lines.append("ðŸ˜â€¯Flows even and VWAP flat â†’ market indecision.")
    else:
        lines.append("ðŸ”„â€¯Mixed: Volume and VWAP diverging (possible churn/false breakout).")
    lines.append(f"Currentâ€¯Volâ€¯Imbalance:â€¯{last['Vol_imbalance']:.2f},â€¯Î”VWAP:â€¯{last['Î”VWAP']:.2f}")
    return "\n".join(lines)

st.info(interpret_volume_vwap(df_feat))

# ---- ALT VIEW (optional small chart for reference) ----
st.subheader("ðŸ“ˆâ€¯Miniâ€¯Timelineâ€¯(Visualâ€¯Aid)")
chart = alt.Chart(df_feat.reset_index()).transform_fold(
    ["Vol_imbalance","Î”VWAP"],as_=["Metric","Value"]
).mark_line().encode(
    x="timestamp:T",color="Metric:N",y="Value:Q",tooltip=["timestamp","Metric","Value"]
).interactive()
st.altair_chart(chart,use_container_width=True)
