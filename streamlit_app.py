import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import altair as alt

# ======================================
st.set_page_config("Ruleâ€‘Basedâ€¯Intradayâ€¯Optionâ€¯Signals", layout="wide")
st.title("ðŸ“Šâ€¯Ruleâ€‘Basedâ€¯Intradayâ€¯Optionâ€¯Signalâ€¯Systemâ€¯â€“â€¯Volumeâ€¯Sentimentâ€¯Edition")

# ---- SIDEBAR ----
rolling_n = st.sidebar.number_input("Rollingâ€¯windowâ€¯(bars)", 3, 60, 5)
spread_cutoff = st.sidebar.slider("Maxâ€¯bidâ€‘askâ€¯spreadâ€¯%", 0.0, 1.0, 0.2)
basis = st.sidebar.radio("Topâ€‘strikeâ€¯rankingâ€¯basis", ["Openâ€¯Interest", "Volume"])
num_strikes = st.sidebar.number_input("Topâ€¯strikesâ€¯byâ€¯basis", 1, 30, 6)
st.sidebar.markdown("Uploadâ€¯**Optionâ€‘Chainâ€¯CSVâ€¯files**â€¯ðŸ‘‡")

uploaded = st.file_uploader(
    "Dropâ€¯CSVâ€¯filesâ€¯(multipleâ€¯allowed)", type=["csv"], accept_multiple_files=True
)
if not uploaded:
    st.info("â¬…ï¸â€¯Uploadâ€¯CSVsâ€¯toâ€¯start.")
    st.stop()

# ---- LOAD ----
frames = []
for f in uploaded:
    try:
        base = f.name.replace(".csv", "")
        ts = datetime.strptime(
            base.split("_")[-2] + "_" + base.split("_")[-1], "%d%m%Y_%H%M%S"
        )
    except Exception:
        ts = datetime.now()
    df = pd.read_csv(f)
    df["timestamp"] = ts
    frames.append(df)
raw = pd.concat(frames, ignore_index=True).sort_values("timestamp")
st.success(f"âœ…â€¯Loadedâ€¯{len(uploaded)}â€¯file(s),â€¯{len(raw)}â€¯rows.")

# ---- CLEAN ----
def clean_data(df, cuto=0.2):
    df = df.copy()
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
    req = ["CE_buyPrice1", "CE_sellPrice1", "PE_buyPrice1", "PE_sellPrice1"]
    avail = [c for c in req if c in df.columns]
    df = df[(df[avail] > 0).all(axis=1)]
    df["mid_CE"] = (df["CE_buyPrice1"] + df["CE_sellPrice1"]) / 2
    df["mid_PE"] = (df["PE_buyPrice1"] + df["PE_sellPrice1"]) / 2
    df["mid_CE"].replace(0, np.nan, inplace=True)
    df["spread_pct"] = abs(df["CE_sellPrice1"] - df["CE_buyPrice1"]) / df["mid_CE"]
    df = df[df["spread_pct"] < cuto]
    if "CE_expiryDate" in df.columns:
        df["CE_expiryDate"] = pd.to_datetime(df["CE_expiryDate"], errors="coerce")
        df["days_to_expiry"] = (df["CE_expiryDate"] - df["timestamp"]).dt.days
    else:
        df["days_to_expiry"] = 1
    df["days_to_expiry"].fillna(1, inplace=True)
    df["Î¸_adj_CE"] = df["CE_lastPrice"] / np.sqrt(df["days_to_expiry"].clip(lower=1))
    df["Î¸_adj_PE"] = df["PE_lastPrice"] / np.sqrt(df["days_to_expiry"].clip(lower=1))
    return df


df = clean_data(raw, spread_cutoff)

# ---- FEATURE BUILDER ----
def compute_features(df, rolling_n=5, top_n=6, basis="Openâ€¯Interest"):
    df = df.copy().sort_values("timestamp")
    df["CE_vol_delta"] = (
        df.groupby("CE_strikePrice")["CE_totalTradedVolume"].diff().fillna(0)
    )
    df["PE_vol_delta"] = (
        df.groupby("CE_strikePrice")["PE_totalTradedVolume"].diff().fillna(0)
    )
    df["total_vol"] = df["CE_vol_delta"] + df["PE_vol_delta"]
    df["total_OI"] = df["CE_openInterest"] + df["PE_openInterest"]

    metric = "total_OI" if basis.startswith("Open") else "total_vol"
    mean_strike = df.groupby("CE_strikePrice")[metric].mean()
    top_strikes = mean_strike.nlargest(top_n)
    covered_pct = round(100 * top_strikes.sum() / mean_strike.sum(), 2)
    df = df[df["CE_strikePrice"].isin(top_strikes.index)]

    agg = df.groupby("timestamp").agg(
        {
            "CE_lastPrice": "mean",
            "PE_lastPrice": "mean",
            "CE_openInterest": "sum",
            "PE_openInterest": "sum",
            "CE_changeinOpenInterest": "sum",
            "PE_changeinOpenInterest": "sum",
            "CE_vol_delta": "sum",
            "PE_vol_delta": "sum",
            "CE_impliedVolatility": "mean",
            "PE_impliedVolatility": "mean",
        }
    )

    # base deltas
    agg["Î”Price_CE"] = agg["CE_lastPrice"].diff()
    agg["Î”OI_CE"] = agg["CE_changeinOpenInterest"].diff()
    agg["Î”Price_PE"] = agg["PE_lastPrice"].diff()
    agg["Î”OI_PE"] = agg["PE_changeinOpenInterest"].diff()
    agg["IV_skew"] = agg["CE_impliedVolatility"] - agg["PE_impliedVolatility"]
    agg["Î”IV"] = agg["IV_skew"].diff()
    agg["PCR_OI"] = agg["PE_openInterest"] / agg["CE_openInterest"].replace(0, np.nan)
    agg["Î”PCR"] = agg["PCR_OI"].diff()
    total_vol = agg["CE_vol_delta"] + agg["PE_vol_delta"]

    # rolling measures
    agg["Volume_spike"] = total_vol / total_vol.rolling(rolling_n).mean()

    # VWAP + imbalance
    agg["VWAP"] = (
        (agg["CE_lastPrice"] * agg["CE_vol_delta"] + agg["PE_lastPrice"] * agg["PE_vol_delta"])
        / (agg["CE_vol_delta"] + agg["PE_vol_delta"]).replace(0, np.nan)
    ).fillna(method="ffill")
    agg["Î”VWAP"] = agg["VWAP"].diff()
    agg["Vol_imbalance"] = (agg["CE_vol_delta"] - agg["PE_vol_delta"]) / (
        agg["CE_vol_delta"] + agg["PE_vol_delta"]
    ).replace(0, np.nan)
    agg["Absorption_idx"] = agg["CE_vol_delta"].abs() / (agg["Î”OI_CE"].abs() + 1)

    # ðŸ”¹ new deepâ€‘volume metrics
    agg["Volume_Momentum"] = (total_vol / total_vol.shift(rolling_n)) - 1
    agg["Volume_Pressure_Score"] = (
        np.sign(agg["Î”Price_CE"].fillna(0)) * agg["CE_vol_delta"].fillna(0)
    ).rolling(rolling_n, min_periods=3).sum()

    agg["Corr_PriceVol"] = (
        agg["Î”Price_CE"].rolling(rolling_n, min_periods=3)
        .corr(agg["CE_vol_delta"])
    ).fillna(0)
    agg["Corr_IVVol"] = (
        agg["Î”IV"].rolling(rolling_n, min_periods=3)
        .corr(agg["Volume_spike"])
    ).fillna(0)
    agg["Cum_tick_flow"] = np.cumsum(
        np.sign(agg["Î”Price_CE"].fillna(0)) * agg["CE_vol_delta"]
    )

    agg.fillna(0, inplace=True)
    return agg, covered_pct


df_feat, covered_pct = compute_features(df, rolling_n, num_strikes, basis)
st.caption(f"Topâ€¯{num_strikes}â€¯strikes coverâ€¯â‰ˆâ€¯{covered_pct}%â€¯ofâ€¯totalâ€¯{basis.lower()}.")

# ---- REGIME / SIGNAL ----
def detect_regime(row):
    reg, bias = "quiet", "neutral"
    if row["Î”Price_CE"] * row["Î”OI_CE"] > 0 and row["Volume_spike"] > 1:
        reg = "trend"
    elif abs(row["Î”Price_CE"]) < 0.05 and abs(row["Î”OI_CE"]) < 1000:
        reg = "range"
    elif abs(row["Î”Price_CE"]) > 0.2 and row["Volume_spike"] > 1.5 and row["Î”IV"] > 0:
        reg = "breakout"
    elif row["Î”Price_CE"] > 0 and row["Î”OI_CE"] < 0 and row["Î”IV"] < 0:
        reg = "exhaustion"
    if row["PCR_OI"] < 0.8:
        bias = "bullish"
    elif row["PCR_OI"] > 1.2:
        bias = "bearish"
    return reg, bias


def generate_signal(row):
    if row["regime"] == "trend" and row["bias"] == "bullish":
        return "BUY_CALL"
    if row["regime"] == "trend" and row["bias"] == "bearish":
        return "BUY_PUT"
    if row["regime"] == "range":
        return "SELL_STRANGLE"
    if row["regime"] == "breakout":
        return "MOMENTUM_TRADE"
    if row["regime"] == "exhaustion":
        return "EXIT_POSITION"
    return "HOLD"


df_feat[["regime", "bias"]] = df_feat.apply(
    detect_regime, axis=1, result_type="expand"
)
df_feat["signal"] = df_feat.apply(generate_signal, axis=1)
df_feat["signal_numeric"] = (
    df_feat["signal"]
    .map(
        {
            "BUY_CALL": 1,
            "BUY_PUT": 1,
            "MOMENTUM_TRADE": 1,
            "SELL_STRANGLE": 0,
            "HOLD": 0,
            "EXIT_POSITION": -1,
        }
    )
    .fillna(0)
)

# ---- HUMAN INTERPRETATION ----
def signal_summary(r):
    txt = []
    if r["Vol_imbalance"] > 0.3:
        txt.append("Callâ€‘side volumeâ€¯dominantâ€¯â†’â€¯bullishâ€¯lean.")
    elif r["Vol_imbalance"] < -0.3:
        txt.append("Putâ€‘side volumeâ€¯dominantâ€¯â†’â€¯bearishâ€¯lean.")
    else:
        txt.append("Flowsâ€¯balanced.")
    if r["Î”VWAP"] > 0:
        txt.append("VWAPâ€¯risingâ€¯â†’â€¯buyersâ€¯liftingâ€¯offers.")
    elif r["Î”VWAP"] < 0:
        txt.append("VWAPâ€¯fallingâ€¯â†’â€¯sellersâ€¯hittingâ€¯bids.")
    if r["Volume_Momentum"] > 0:
        txt.append("Volumeâ€¯momentumâ€¯â†‘â€¯â†’â€¯activityâ€¯building.")
    else:
        txt.append("Volumeâ€¯momentumâ€¯â†“â€¯â†’â€¯participationâ€¯dropping.")
    if r["Volume_Pressure_Score"] > 0:
        txt.append("Netâ€¯buyingâ€¯pressureâ€¯inâ€¯window.")
    elif r["Volume_Pressure_Score"] < 0:
        txt.append("Netâ€¯sellingâ€¯pressureâ€¯inâ€¯window.")
    if r["Corr_PriceVol"] > 0.5:
        txt.append("Strongâ€¯+corrâ€¯(priceâ€‘volume)â€¯â†’â€¯convictionâ€¯buying.")
    elif r["Corr_PriceVol"] < -0.5:
        txt.append("Negativeâ€¯corrâ€¯â†’â€¯absorptionâ€¯/â€¯profitâ€‘taking.")
    concl = "Neutralâ€¯biasâ€¯â€“â€¯range likely."
    if r["Vol_imbalance"] > 0.3 and r["Î”VWAP"] > 0:
        concl = "ðŸ“ˆâ€¯CEâ€¯pricesâ€¯likelyâ€¯toâ€¯rise."
    elif r["Vol_imbalance"] < -0.3 and r["Î”VWAP"] < 0:
        concl = "ðŸ“‰â€¯PEâ€¯pricesâ€¯likelyâ€¯toâ€¯rise."
    txt.append("ðŸ§­â€¯" + concl)
    return "\n".join(txt)


df_feat["Implied_Signal_Text"] = df_feat.apply(signal_summary, axis=1)

# ---- DASHBOARD SENTIMENT ----
def summarize_sentiment(df):
    r = df.iloc[-1]
    score = 0
    if r["Vol_imbalance"] > 0.3:
        score += 1
    elif r["Vol_imbalance"] < -0.3:
        score -= 1
    if r["Î”VWAP"] > 0:
        score += 1
    elif r["Î”VWAP"] < 0:
        score -= 1
    if r["Volume_Pressure_Score"] > 0:
        score += 1
    elif r["Volume_Pressure_Score"] < 0:
        score -= 1

    if score >= 2:
        return "ðŸŸ¢â€¯Market moderatelyâ€¯bullishâ€¯withâ€¯risingâ€¯participation."
    elif score <= -2:
        return "ðŸ”´â€¯Market moderatelyâ€¯bearishâ€¯withâ€¯sellingâ€¯pressure."
    else:
        return "ðŸŸ§â€¯Market neutralâ€¯/â€¯mixedâ€¯flows."


st.subheader("ðŸ§­â€¯Overallâ€¯Marketâ€¯Sentiment")
st.success(summarize_sentiment(df_feat))

# ---- METRICS ----
lat = df_feat.iloc[-1]
c1, c2, c3, c4 = st.columns(4)
c1.metric("PCRâ€¯(OI)", round(float(lat["PCR_OI"]), 2))
c2.metric("Trendâ€¯Bars", int((df_feat["regime"] == "trend").sum()))
c3.metric("Latestâ€¯Signal", lat["signal"])
c4.metric("Rows", len(df_feat))

# ---- SIGNAL TABLE ----
st.subheader("ðŸ“‹â€¯Detailedâ€¯Signalsâ€¯â€“â€¯Fullâ€¯Timeline")
cols_show = [
    "signal",
    "bias",
    "regime",
    "Vol_imbalance",
    "Î”VWAP",
    "Volume_Momentum",
    "Volume_Pressure_Score",
    "Corr_PriceVol",
    "Absorption_idx",
    "Corr_IVVol",
    "PCR_OI",
    "Implied_Signal_Text",
]
st.dataframe(df_feat[cols_show], use_container_width=True)

# ---- INTERPRETATION ----
st.subheader("ðŸ”â€¯Volumeâ€¯Imbalanceâ€¯&â€¯VWAPâ€¯Insights")
def interpret_volume_vwap(agg):
    last = agg.iloc[-1]
    msg = []
    if last["Vol_imbalance"] > 0.3 and last["Î”VWAP"] > 0:
        msg.append("âœ…â€¯Callâ€‘sideâ€¯volumeâ€¯+â€¯risingâ€¯VWAPâ€¯â†’â€¯bullishâ€¯flow.")
    elif last["Vol_imbalance"] < -0.3 and last["Î”VWAP"] < 0:
        msg.append("âš ï¸â€¯Putâ€‘sideâ€¯volumeâ€¯+â€¯fallingâ€¯VWAPâ€¯â†’â€¯bearishâ€¯bias.")
    else:
        msg.append("ðŸ˜â€¯Mixedâ€¯orâ€¯neutralâ€¯flows.")
    msg.append(f"Volâ€¯Imbalanceâ€¯{last['Vol_imbalance']:.2f}â€¯|â€¯Î”VWAPâ€¯{last['Î”VWAP']:.2f}")
    return "\n".join(msg)


st.info(interpret_volume_vwap(df_feat))

# ---- MINI BAR CHARTS ----
st.subheader("ðŸ“Šâ€¯Miniâ€¯Timelineâ€¯â€“â€¯Volumeâ€¯Imbalanceâ€¯&â€¯Î”VWAP")
chart_df = df_feat.reset_index()[["timestamp", "Vol_imbalance", "Î”VWAP"]].copy()
chart_df["timestamp"] = pd.to_datetime(chart_df["timestamp"], errors="coerce")

bars_imb = (
    alt.Chart(chart_df)
    .mark_bar(color="#FFA500", opacity=0.7)
    .encode(x="timestamp:T", y=alt.Y("Vol_imbalance:Q", title="Volâ€¯Imbalanceâ€¯(Callâ€‘Put)"))
)
bars_vwap = (
    alt.Chart(chart_df)
    .mark_bar(color="#00CC66", opacity=0.7)
    .encode(x="timestamp:T", y=alt.Y("Î”VWAP:Q", title="Î”VWAPâ€¯(Priceâ€¯Drift)"))
)
final_chart = alt.vconcat(bars_imb, bars_vwap).resolve_scale(y="independent")
st.altair_chart(final_chart, use_container_width=True)
